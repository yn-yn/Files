


> Written with [StackEdit中文版](https://stackedit.cn/).

# Obstacle detection and tracking method for autonomous vehicle based on three-dimensional LiDAR [基于三维激光雷达的自主车辆障碍物检测和跟踪方法]

> 参考文献: [Obstacle detection and tracking method for autonomous vehicle based on three-dimensional LiDAR](https://journals.sagepub.com/doi/full/10.1177/1729881419831587)

## Why LiDAR
> Computer vision-based approach is very susceptible to light, causing poor detection and tracking results when light is weak. LiDAR is widely used in the detection and tracking of autonomous vehicle as its extraordinary ability to obtain the basic shape, distance measurement, and position of the obstacle.

基于**计算机视觉的方法非常容易受到光线的影响**，当光线较弱时，会导致检测和跟踪结果不佳。LiDAR被广泛用于自主车辆的检测和跟踪，因为它具有获得障碍物的基本形状、距离测量和位置的非凡能力。

## Methods
> This article proposes a new approach to improve static/moving obstacle detection and tracking. Firstly, road point-cloud data are removed from the point-cloud data of one frame and the reuse of useful non-obstacle cells is carried out, then, the proposed clustering algorithm is used to cluster the obstacle cells quickly. When it comes to obstacle detection, we detect static obstacles by multi-frame before detecting moving obstacles. And finally, the proposed dynamic tracking point model and Kalman filter algorithm are applied to track the moving obstacles. The good performance in the real urban scenarios shows that the pro-posed approach has high reliability and can detect and track moving obstacle well.

本文提出了一种新的方法来改进静态/移动障碍物的检测和跟踪。首先，将道路点云数据从一帧的点云数据中删除，并对有用的非障碍物单元进行再利用，然后，使用所提出的**聚类算法对障碍物单元进行快速聚类**。当涉及到障碍物检测时，我们**在检测移动障碍物之前通过多帧检测静态障碍物**。最后，提出的**动态跟踪点模型和卡尔曼滤波算法**被用于跟踪移动的障碍物。在实际城市场景中的良好表现表明，所提出的方法具有较高的可靠性，能够很好地检测和跟踪移动障碍物。

## ① Obstacle clustering algorithm

工具: HDL-64E LiDAR

![](https://raw.githubusercontent.com/yn-yn/image1/master/2022/10/19/MTx6mi14wYyJfEGP.png =500x)

> Because of the spacing between different laser lines of HDL-64E, and over-segmentation of road, the point-cloud data of one frame after road segmentation cannot present the surrounding environment around autonomous vehicle precisely. Therefore, we add additional cells to enrich the useful information we once missed. If there are two obstacle cells whose intermediate cells are several non-obstacle cells, and one obstacle cell’s maximum point-cloud height is similar to the other, then we will change the intermediate non-obstacle cells into obstacle cells and assign the attribute values of the two obstacle cells to the non-obstacle cells. However, if the quantity of intermediate non-obstacle cells exceeds 3, no additional non-obstacle cell is changed into obstacle cell. When the LiDAR is installed at the position which is away about 2.2 m from the ground, the distance between different laser lines is about 2.3 m at the distance of 40 m away from autonomous vehicle, so changing possible non-obstacle cells into obstacle cells when the non-obstacle cells which are no more than three between two obstacle cells whose maximum point-cloud height is similar to the other is reasonable, as the maximum length of added obstacle cells is 1.2 m. Changing useful non-obstacle cells into obstacle cells can greatly enhance the ability of point-cloud data to present the surrounding environment around autonomous vehicle. Figure 3 is the occupancy grid map which has added additional useful cells. The middle blue box represents the position of autonomous vehicle, and the left figure is the original point-cloud data after road segmentation, and the right figure is the occupancy grid map with added cells.

由于HDL-64E的不同激光线之间的间隔，以及道路的过度分割，道路分割后的一帧**点云数据不能准确地呈现自主车辆周围的环境**。因此，我们增加了额外的单元来丰富我们曾经错过的有用信息。如果有两个障碍物单元的中间单元是几个非障碍物单元，并且一个障碍物单元的最大点云高度与另一个相似，那么我们将把中间的非障碍物单元改为障碍物单元，并将两个障碍物单元的属性值分配给非障碍物单元。然而，如果中间非障碍单元的数量超过3个，就不会有额外的非障碍单元被改变为障碍单元。当LiDAR安装在离地面约2.2米的位置时，在离自主车辆40米的距离上，不同激光线之间的距离约为2.3米，因此，当两个最大点云高度相近的障碍单元之间的非障碍单元不超过3个时，将可能的非障碍单元改为障碍单元是合理的，因为新增障碍单元的最大长度为1.2米。将有用的非障碍物单元改为障碍物单元，可以大大增强点云数据对自主车辆周围环境的呈现能力。图3是添加了额外有用单元的占用网格图。中间的蓝框代表自主车辆的位置，左图是道路分割后的原始点云数据，右图是添加了单元的占用网格图。

![](https://raw.githubusercontent.com/yn-yn/image1/master/2022/10/24/15PzXMGYHXiSX4FW.png)

### Eight-neighbor cells clustering algorithm

> In this article, we propose an eight-neighbor cells clustering algorithm, which can **quickly complete the cells clustering**.

![](https://raw.githubusercontent.com/yn-yn/image1/master/2022/10/19/Q2YQxTnADX8npYcu.png =400x)

![](https://raw.githubusercontent.com/yn-yn/image1/master/2022/10/19/Mk89qNmQrCPpuM7W.png =400x)

## ② Static obstacle detection

> The static obstacle detection is carried out on the basis of the results obtained by eight-neighbor cells clustering algorithm. First of all, clustering results are used to detect the static obstacles in a single frame. Since the occlusion of moving obstacles such as moving vehicles and the spacing between different laser lines of HDL-64E LiDAR, it is hard to detect the roadside and other static obstacles in a single frame. Therefore, the method of multi-frame fusion is proposed to improve static obstacle detection, and we found that the static obstacle detection result is much better than the detection result in a single frame.

静态障碍物检测是在 eight-neighbor cells clustering algorithm 得到的结果基础上进行的。首先，聚类结果被用来检测单帧中的静态障碍物。

由于移动车辆等移动障碍物的遮挡以及HDL-64E LiDAR不同激光线之间的间隔，很难在单帧中检测到路边和其他静态障碍物。因此，我们提出了**多帧融合的方法来改进静态障碍物的检测**，并发现静态障碍物的检测结果要比单帧的检测结果好得多。

>There are mainly two feature templates of static obstacle:
(1) the first feature template contains the roadside and the adjacent static obstacle such as buildings. The length and width of this feature template are obviously larger than the length and width of the moving obstacle such as moving vehicles, pedestrians, and so on. The green part of box no.1 in Figure 5 is the static obstacle detection result by matching with this kind of feature template.
(2) The second feature template only contains the roadside, and the salient feature of this kind of template is very narrow and its height is significantly lower than the moving bus and trucks in the expressway. As shown in Figure 5, the green part of box no. 2 is the static obstacle detection result by matching with this kind of feature template.

静态障碍物主要有两个特征模板。
(1) 第一个特征模板包含路边和相邻的静态障碍物，如建筑物。**这个特征模板的长度和宽度明显大于移动障碍物（如移动的车辆、行人等）的长度和宽度**。图5中1号方框中的绿色部分就是与这种特征模板匹配的静态障碍物检测结果。
(2）第二种特征模板只包含路边，这种模板的突出特征是非常狭窄，其高度明显低于高速公路上行驶的客车和卡车。如图5所示，2号方框中的绿色部分是与这种特征模板匹配后的静态障碍物检测结果。

![](https://raw.githubusercontent.com/yn-yn/image1/master/2022/10/19/NO01GEHBhCxIznEG.png =450x)

> However, we can only get parts of static obstacle detection results through the template matching method, and the complex traffic scenarios determine that the template matching method cannot get all the static obstacle detection results in a single frame. As shown in box no.3 of Figure 5, the clustering result which is static obstacle but not colored green is wrongly detected. Therefore, we propose a multi-frame fusion method to detect static obstacles.

然而，我们只能通过模板匹配方法获得部分静态障碍物检测结果，复杂的交通场景决定了模板匹配方法无法在单帧中获得所有静态障碍物检测结果。如图5中的方框3所示，属于静态障碍物但不是绿色的聚类结果是错误的检测。因此，我们提出一种多帧融合的方法来检测静态障碍物。

**multi-frame fusion method 原理掠过, 只展示结果 ↓**
![](https://raw.githubusercontent.com/yn-yn/image1/master/2022/10/19/uW2AmJTnZIOO6Yyz.png =900x)

## ③ Moving obstacle detection and tracking process

> The purpose of moving obstacle detection and tracking is to obtain the movement state of the moving obstacle, so as to predict the possible state and trajectory of the moving obstacle, which is of great significance to path planning and decision-making of autonomous vehicle. In this article, a moving obstacle detection method based on the detected travelable area and feature templates matching is proposed. Data association is carried out on the basis, and moving obstacle is tracked by the improved dynamic tracking point model and Kalman filter.

移动障碍物检测和跟踪的目的是为了获得移动障碍物的运动状态，从而预测移动障碍物的可能状态和轨迹，这对自主车辆的路径规划和决策具有重要意义。文章提出了一种**基于检测到的可行驶区域和特征模板匹配的移动障碍物检测方法**。在此基础上进行数据关联，并通过**改进的动态跟踪点模型和卡尔曼滤波器**对移动障碍物进行跟踪。

![](https://raw.githubusercontent.com/yn-yn/image1/master/2022/10/19/8NPXvSRYdBiOTMBK.png =450x)


## ④ Experimental results and analysis

> Our experimental vehicle is JJUV-5, the champion of 2016 China Intelligent Vehicle Future Challenge (see Figure 11). The main sensors include a velodyne HDL-64E LiDAR, a set of RTK-GPS system, and an Inertial+INS, and the computer is equipped with Intel quad-core i5- 3350p processor.

**实验车**: 2016年中国智能汽车未来挑战赛的冠军车型JJUV-5

**主要传感器**: 一个velodyne HDL-64E LiDAR，一套RTK-GPS系统，以及一个Inertial+INS，计算机配备英特尔四核i5- 3350p处理器。

![](https://raw.githubusercontent.com/yn-yn/image1/master/2022/10/19/pbbzSyL7njBI7RyA.png =400x)

![](https://raw.githubusercontent.com/yn-yn/image1/master/2022/10/19/UrQmhCBTSWVIe77y.png =500x)





<!--stackedit_data:
eyJoaXN0b3J5IjpbMTYzMzQ3MjUzM119
-->