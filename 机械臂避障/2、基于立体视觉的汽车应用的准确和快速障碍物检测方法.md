


> Written with [StackEdit中文版](https://stackedit.cn/).

# Accurate and fast obstacle detection method for automotive applications based on stereo vision (基于立体视觉的汽车应用的准确和快速障碍物检测方法)

> 参考文献: [Accurate and fast obstacle detection method for automotive applications based on stereo vision](https://ieeexplore.ieee.org/document/8373249)

采用相机: 基于立体视觉

## INTRO
> The proposed algorithm searches on the depth map along vertical direction for pixels having the same disparity. Having the same disparity indicates that these pixels are from the same object, and such object is an obstacle on the road. After implementation, the average processing time of the proposed obstacle detection algorithm for HD 720p image requires only 4.0 milliseconds (ms) on Intel Core i7 3.6 GHz processor, and 16.3 ms on an embedded system, i.e., the NVIDIA Jetson TX1. The detection performance based on stereo vision is more precise and faster compared with 2-D image object recognition. By directly comparing the purchasing price, the hardware cost to use stereo camera is also much lower than a RADAR or LiDAR system.

该算法在深度图上**沿垂直方向搜索具有相同差异的像素**。具有相同的差异表明这些像素来自同一个物体，而这个物体就是道路上的障碍物。实施后，所提出的障碍物检测算法**在英特尔酷睿i7 3.6 GHz处理器上**的平均处理时间仅为**4.0 ms**，而**在嵌入式系统（即英伟达Jetson TX1）上**则为**16.3 ms**。与二维图像物体识别相比，基于立体视觉的检测性能更加精确和快速。通过直接比较购买价格，使用立体相机的硬件成本也比雷达或激光雷达系统低得多。

==The operating environment is composed of Linux for Tegra R24.2.1, CUDA 8.0, OpenCV4Tegra 2.4.13, ZED SDK 2.0 on Jetson TX1. The resolution is 720P, i.e. 2560x720 for a stereo pair.==

## 目标/功能
> In light of the need to improve driving safety, a significant number of Advanced Driver Assistance Systems (ADAS) have been developed recently, including adaptive cruise control, blind-spot monitoring, forward collision warning, automatic emergency braking, lane departure warning, etc.

鉴于提高驾驶安全的需要，最近开发了大量的高级驾驶辅助系统（ADAS），包括**自适应巡航控制、盲点监测、前方碰撞警告、自动紧急制动、车道偏离警告**等。

## 创新点
> The previous obstacle detection methods for the automotive environment have been mainly based on capturing features and using machine learning, or deep learning to recognize objects. The main disadvantage of these methods is their inability to recognize obstacles that were never included in the database. Furthermore, several real-time stereo vision hardware systems have been developed during the past decades. Though stereo vision can identify the correct distance between objects in images and cameras, the method re-building the 3-D space structure is complex and time-consuming. Therefore, this study proposed an algorithm of using depth map produced by stereo vision along with a monocular camera model to simplify the obstacle analysis. It increases very tiny calculation, and can achieve higher detection accuracy than feature-based image processing methods.

以前用于汽车环境的障碍物检测方法主要是**基于捕捉特征和使用机器学习，或深度学习来识别物体**。这些方法的主要**缺点是无法识别那些从未被纳入数据库的障碍物**。此外，在过去的几十年里，已经开发了几个实时立体视觉硬件系统。虽然立体视觉可以识别图像和摄像机中物体之间的正确距离，但**重新建立三维空间结构的方法是复杂和耗时的**。

因此，本研究提出了一种**利用立体视觉产生的深度图**与**单目相机**模型来简化障碍物分析的算法。它**增加了非常微小的计算，并能达到比基于特征的图像处理方法更高的检测精度**。

## 深度测量方法
> The majority of the studies have different approaches to generate dense disparity map. The common approaches include: 
> (1) local algorithms, for example, Block Matching, 
> (2) global algorithms, for instance, Graph Cut and Dynamic Programming, 
> (3) semi-global algorithms which combines local and global algorithms, 
> (4) IC chips with stereo vision by hardware circuit which have been applied to Xbox Kinect and Intel RealSense. 
> The proposed study utilized Stereolab ZED Camera to provide disparity map (Figure 4), and use triangulation to estimate the distance in the map. The maximum distance estimated in the depth map was 80 meters majorly due to the resolution limitation. As shown in Figure 5, if the disparity of the object p in two cameras image is t (pixel), the focus of camera is f (pixel), and the distance between two optical centers is b (mm), then the distance between the object p and the camera is d =bf/t (mm).

大多数的研究都有不同的方法来生成密集的视差图。常见的方法包括：
（1）局部算法，如块状匹配；
（2）全局算法，如图谱切割和动态编程；
（3）结合了局部和全局算法的半全局算法；
（4）通过硬件电路实现立体视觉的IC芯片，这已应用于Xbox Kinect和Intel RealSense。
本研究利用Stereolab ZED相机来提供视差图（图4），并使用三角法来估计图中的距离。由于分辨率的限制，深度图中估计的最大距离为80米。

![](https://raw.githubusercontent.com/yn-yn/image1/master/2022/10/18/U2nNWhlpKfcsC9Cr.png =600x)

如图5所示，如果两台摄像机图像中的物体p的差异是t（像素），摄像机的焦点是f（像素），两个光学中心之间的距离是b（毫米），那么物体p和摄像机之间的距离是d=bf/t（毫米）。

![](https://raw.githubusercontent.com/yn-yn/image1/master/2022/10/18/AczvXSZjTVla3qiD.png =300x)

## 相机分辨率选择
> ZED camera's output resolution included several quality formats of depth map, i.e., 1080P, 720P and WVGA. Table 1 shows the depth map processing time of ZED camera on Jetson TX1. If the resolution is higher, the distance of estimation will be farther, but the processing time will also be longer. In order to achieve over 10 FPS (frames per second) in real-time processing and far enough distance estimation, we choose 720P (2560x720 for a stereo pair) and the performance mode.

ZED相机的输出分辨率包括几种质量格式的深度图，即1080P、720P和WVGA。表1显示了ZED相机在Jetson TX1上的深度图处理时间。如果分辨率越高，估计的距离会越远，但处理时间也会越长。为了在实时处理中实现超过10 FPS（每秒帧数）和足够远的距离估计，我们选择720P（2560x720的立体声对）和性能模式。

![](https://raw.githubusercontent.com/yn-yn/image1/master/2022/10/18/wrabiafiMkFOIrxb.png =600x)

## 障碍物检测

> Figure 6(a) shows the view from forward camera. The distance between two succeeding red lines is, said 1 meter, and the blue line is the horizon. The blue object is obstacle, the depth value between two red lines is equal to the value of line in the bottom. As shown in Figure 6(b), the obstacle is identified as distance between 1 and 2 meters. Figure 6(c) illustrates that when the algorithm search toward the vertical direction, the disparity values of pixels keep the same as the bottom one. Such finding reveals that these pixels are not on the ground, which in turn, should be an obstacle.

图6(a)显示了来自前方摄像机的视图。两条连续的红线之间的距离为1米，蓝线为地平线。蓝色物体是障碍物，两条红线之间的深度值等于底部的线值。如图6(b)所示，障碍物被识别为距离在1到2米之间。图6(c)表明，当算法向垂直方向搜索时，像素的差异值与底部的差异值保持一致。这样的发现表明，这些像素不在地面上，而地面应该是一个障碍物。

![](https://raw.githubusercontent.com/yn-yn/image1/master/2022/10/18/118Cha4B1oFAvKgn.png =400x)

## 参数确定

> Figure 7 shows the simplification of depth map. Assume that the distance range is within 80 meters and the value of a depth map is from 0 to 255, i.e., 256 levels, the distance range of each level is only 31 cm. Such unit is too small for common objects on the road so that the depth map of each level would not cover a complete obstacle. Moreover, such elaborate partition is too sensitive to the pitch angle jittering of the camera due to driving vibration. As shown in Figure 7 (a), we find that the depth map of 256 level involves too few object information for our method. Hence, we reduce the levels of depth map to 16 to increase the continuity of all of the objects, as shown in Figure 7 (b). This parameter of level number is determined from experiments which we will go into more details in the following. 

图7显示了深度图的简化情况。假设距离范围在80米以内，深度图的值从0到255，也就是256级，每级的距离范围只有31厘米。这样的单位对于道路上的普通物体来说太小了，所以每个级别的深度图不会覆盖完整的障碍物。此外，这种精心设计的分区对驾驶振动引起的摄像机俯仰角抖动过于敏感。如图7（a）所示，我们发现256级的深度图对我们的方法来说涉及的物体信息太少。因此，我们将深度图的级别减少到16级，以增加所有物体的连续性，如图7（b）所示。这个级别数的参数是根据实验确定的，我们将在下文中详细介绍。

![](https://raw.githubusercontent.com/yn-yn/image1/master/2022/10/18/V6moWJ1a6JgdpDre.png =600x)


## 识别效果

![](https://raw.githubusercontent.com/yn-yn/image1/master/2022/10/18/YoXJz35EB6C1Bkht.png =600x)

![](https://raw.githubusercontent.com/yn-yn/image1/master/2022/10/18/3Eut9fajmI2wnO46.png =600x)

图9显示了分别使用64级、16级和8级的障碍物检测结果。从图9(a)中，我们可以知道64级的结果不太完整，因为轿车没有完全被栏杆覆盖。相比之下，8级的结果，即图9(c)，显示出轿车的一部分被识别为地面。在比较了图9(a)和9(c)之后，我们认为使用16级深度图，如图9(b)所示，可以为这项工作带来最佳的检测性能。

![](https://raw.githubusercontent.com/yn-yn/image1/master/2022/10/18/4INSKUr6HuNZYRYF.png =600x)

## 结果

> In this section, we measure the accuracy for the proposed method. We collected the data from a driving car in different environment, and then picked part of these for experiment. Figure 10 shows the results of obstacle detection of this work. The width of each searching bar is 5 pixels. According to the statistics analysis shown in Table 2, the accuracy reaches 93.6%. The error rate of only 6.4% is mainly caused by the very low obstacles, e.g. the traffic island, in Figure 10 (b).

在这一节中，我们测量了所提方法的准确性。我们在不同的环境中收集了驾驶汽车的数据，然后挑选其中一部分进行实验。图10显示了这项工作的障碍物检测结果。每个搜索栏的宽度为5像素。根据表2中的统计分析，准确率达到93.6%。错误率只有6.4%，这主要是由图10(b)中非常低的障碍物引起的，例如，交通岛。

![](https://raw.githubusercontent.com/yn-yn/image1/master/2022/10/18/ymyBwZU8TKcEUrSr.png =600x)

![](https://raw.githubusercontent.com/yn-yn/image1/master/2022/10/18/6s2ALtPWr6MDxypU.png =600x)

![](https://raw.githubusercontent.com/yn-yn/image1/master/2022/10/18/XZpO0DKoX9NT3880.png =600x)

## 方法比较

![](https://raw.githubusercontent.com/yn-yn/image1/master/2022/10/18/Lp5p7vIaDlNIaImo.png =400x)![](https://raw.githubusercontent.com/yn-yn/image1/master/2022/10/18/3MQstxbyoiFSj2Kq.png =400x)

> Because the simplicity of the proposed method, i.e. using monocular camera model with stable parameters, simplified depth map levels, and simple searching operation, it can be implemented on embedded systems with real-time performance. Choices of parameters affect the computation cost. The fewer depth level used the less computation time required. Besides, the content of the video also affects the computation time. When most obstacles are near, they are identified in the first depth level so that shorter time is required.

由于所提出的方法很简单，即使用具有稳定参数的单眼相机模型、简化的深度图层次和简单的搜索操作，它可以在嵌入式系统上以实时性能实现。参数的选择影响计算成本。**使用的深度级别越少，需要的计算时间就越少**。此外，视频的内容也会影响计算时间。当大多数障碍物在附近时，它们会在第一个深度层中被识别出来，因此需要的时间较短。
<!--stackedit_data:
eyJoaXN0b3J5IjpbMjA5MjUzMDA0N119
-->